{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o caminho da pasta de origem onde estão os arquivos a serem processados\n",
    "pasta_origem = r'C:\\Users\\Pedro Carvalho\\Desktop\\Quanti\\Arquivos_Diarios'  # Colocar a pasta onde seus dados estão\n",
    "\n",
    "# Definindo o caminho da pasta de destino para onde os arquivos extraídos serão salvos\n",
    "pasta_destino = r'C:\\Users\\Pedro Carvalho\\Desktop\\Arquivos_Diarios_Novo'  # Colocar a pasta para onde você quer que seus dados vão\n",
    "\n",
    "# Verifica se a pasta de destino não existe. Caso ela não exista, o código cria essa pasta.\n",
    "if not os.path.exists(pasta_destino):\n",
    "    os.makedirs(pasta_destino)\n",
    "\n",
    "# Itera sobre todos os arquivos na pasta de origem\n",
    "for arquivo in os.listdir(pasta_origem):\n",
    "    # Verifica se o arquivo termina com a extensão .zip (ou seja, se é um arquivo ZIP)\n",
    "    if arquivo.endswith('.zip'):\n",
    "        # Cria o caminho completo para o arquivo ZIP na pasta de origem\n",
    "        caminho_zip = os.path.join(pasta_origem, arquivo)\n",
    "        \n",
    "        # Abre o arquivo ZIP para leitura e o extrai para a pasta de destino\n",
    "        with zipfile.ZipFile(caminho_zip, 'r') as zip_ref:\n",
    "            zip_ref.extractall(pasta_destino)  # Extrai todo o conteúdo do ZIP para a pasta de destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista todos os arquivos presentes na pasta de destino, após a extração\n",
    "arquivos_extraidos = os.listdir(pasta_destino)\n",
    "\n",
    "# Filtra a lista de arquivos extraídos, mantendo apenas os que têm a extensão '.csv'\n",
    "arquivos_csv = [arquivo for arquivo in arquivos_extraidos if arquivo.endswith('.csv')]\n",
    "\n",
    "# Itera sobre todos os arquivos CSV filtrados\n",
    "for arquivo_csv in arquivos_csv:\n",
    "    # Constrói o caminho completo para o arquivo CSV na pasta de destino\n",
    "    caminho_csv = os.path.join(pasta_destino, arquivo_csv)\n",
    "    \n",
    "    # Lê o arquivo CSV em um DataFrame do pandas\n",
    "    df = pd.read_csv(caminho_csv)\n",
    "    \n",
    "    # Exibe uma mensagem informando qual arquivo está sendo lido\n",
    "    print(f\"Lendo arquivo: {arquivo_csv}\")\n",
    "    \n",
    "    # Exibe as primeiras 5 linhas do DataFrame lido (útil para verificar rapidamente o conteúdo)\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa uma lista vazia que vai armazenar os DataFrames\n",
    "lista_dfs = []\n",
    "\n",
    "# Itera sobre todos os arquivos CSV que foram filtrados anteriormente\n",
    "for arquivo_csv in arquivos_csv:\n",
    "    # Constrói o caminho completo para o arquivo CSV na pasta de destino\n",
    "    caminho_csv = os.path.join(pasta_destino, arquivo_csv)\n",
    "    \n",
    "    # Lê o arquivo CSV em um DataFrame do pandas\n",
    "    df = pd.read_csv(caminho_csv)\n",
    "    \n",
    "    # Adiciona o DataFrame lido à lista de DataFrames\n",
    "    lista_dfs.append(df)\n",
    "\n",
    "# Concatena todos os DataFrames da lista em um único DataFrame final\n",
    "df_diarios_final = pd.concat(lista_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição da função que extrai a data e o valor de interesse em cada linha do DataFrame\n",
    "def get_data_e_valor(row):\n",
    "    # Verifica se a coluna 'FE Bid' não é nula. Se for válida, retorna a data e o valor de 'FE Bid'.\n",
    "    if pd.notna(row['FE Bid']):\n",
    "        return pd.Series([row['FE Bid Date'], row['FE Bid']])\n",
    "    \n",
    "    # Se 'FE Bid' não for válido, verifica 'Valuation NAV' e retorna seus dados se válido.\n",
    "    elif pd.notna(row['Valuation NAV']): \n",
    "        return pd.Series([row['Valuation NAV Date'], row['Valuation NAV']])\n",
    "    \n",
    "    # Se 'Valuation NAV' também não for válido, tenta 'FE Generic NAV' e retorna seus dados se válido.\n",
    "    elif pd.notna(row['FE Generic NAV']):\n",
    "        return pd.Series([row['FE Generic NAV Date'], row['FE Generic NAV']])\n",
    "    \n",
    "    # Se nenhuma das anteriores for válida, tenta 'FE NAV' e retorna seus dados se disponível.\n",
    "    elif pd.notna(row['FE NAV']):\n",
    "        return pd.Series([row['FE NAV Date'], row['FE NAV']])\n",
    "    \n",
    "    # Caso contrário, tenta 'Transaction NAV' e retorna os dados correspondentes se for válido.\n",
    "    elif pd.notna(row['Transaction NAV']):\n",
    "        return pd.Series([row['Transaction NAV Date'], row['Transaction NAV']])\n",
    "    \n",
    "    # Se nenhuma das colunas anteriores tiver dados válidos, retorna NaN (vazio).\n",
    "    else:\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "\n",
    "# Aplica a função 'get_data_e_valor' para cada linha do DataFrame 'df_diarios_final'\n",
    "# O resultado vai criar duas novas colunas: 'data' e 'valor', com base na função\n",
    "df_diarios_final[['data', 'valor']] = df_diarios_final.apply(get_data_e_valor, axis=1)\n",
    "\n",
    "# Filtra o DataFrame para selecionar colunas de interesse: 'ISIN', 'data' e 'valor'\n",
    "# Remove as linhas com valores nulos e organiza o DataFrame por 'ISIN' e 'data' em ordem crescente\n",
    "df_diarios_final_amostragem = df_diarios_final[['ISIN', 'data', 'valor']].dropna().sort_values(by=['ISIN', 'data'], ascending=[True, True]).head(250)\n",
    "\n",
    "# Exibe as primeiras 250 linhas da amostra para verificação\n",
    "print(df_diarios_final_amostragem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Pedro Carvalho\\Desktop\\Quanti\\Lote_Inicial\\LoteInicial\\LoteInicial.csv') # Colocar a pasta onde seus dados estão\n",
    "\n",
    "df_filtered = df[df['Dynamic Data Type'] == 'FE Bid']\n",
    "\n",
    "df_filtered = df_filtered.dropna(subset=['ISIN', 'General Reference Date', 'Dynamic Value'])\n",
    "\n",
    "df_selected = df_filtered[['ISIN', 'General Reference Date', 'Dynamic Value']]\n",
    "\n",
    "df_unique = df_selected.drop_duplicates(subset=['ISIN', 'General Reference Date'])\n",
    "\n",
    "df_sorted = df_unique.sort_values(by=['General Reference Date', 'ISIN'], ascending=[True, True])\n",
    "\n",
    "df_final = df_sorted.tail(250)\n",
    "\n",
    "df_final.columns = ['ISIN', 'data', 'valor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena dois DataFrames: 'df_diarios_final_amostragem' e 'df_final'\n",
    "df_quanti_historico = pd.concat([df_diarios_final_amostragem, df_final], ignore_index=True).sort_values(by=['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_quanti_historico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o DataFrame 'df_quanti_historico' em um arquivo CSV chamado 'Historico_Quanti.csv'\n",
    "df_quanti_historico.to_csv('Historico_Quanti12.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
